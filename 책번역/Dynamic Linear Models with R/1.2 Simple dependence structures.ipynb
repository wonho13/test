{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Simple dependence structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간이력 해석에서 가장 주요한 목적은 예측입니다. 단변수 또는 다변수 시간이력은 랜덤 변수 또는 벡터 ($Y_t : t=1,2,\\dots$, 여기서 $t$는 시간)에 의해 확률적으로 기술됩니다. 단순한 경우로 시간이 균일하게 분포된 경우를 생각해 봅시다. 예를들어 $Y_t$는 $m$ 채권의 그날 가격 또는 제품의 월별 판매가로 생각할 수 있습니다. n개의 관측치 $Y_{1:n}=y_{1:n}$이 주어졌을 때 $n+1$에서의 관측 값 $Y_{n+1}$를 예측하는 것이 문제입니다. 첫번째로 시간이력 간의 연관성을 합리적으로 가정할 필요가 있습니다. 만약 시간이력 $Y_t$에 대한 확률법칙을 결정할 수 있다면 $n\\geq1$에서 결합확률밀도 $\\pi(y_1,\\dots,y_n)$을 알수 있고, 다음과 같이 예측 밀도를 계산하여 베이지안 예측을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\pi(y_{n+1}|y_{1:n})=\\frac{\\pi(y_{1:n+1})}{\\pi(y_{1:n})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로는 결확확률밀도 $\\pi(y_1,\\dots,y_n)$을 직접 결정하는 것은 쉽지 않으며, 변수모델을 적용하여 좀더 쉽게 결정할 수 있습니다. 즉 확률과정을 만드는 특정 변수 $\\theta$를 설정하고 그 $\\theta$에 대한 $(Y_1,\\dots,Y_n)$의 조건부 확률을 표현하는 것이 더 간단할 수 있습니다. 적절한 특성 변수 $\\theta$는 유한 또는 무한 차원일 수 있습니다. 즉 $\\theta$는 랜덤벡터일 수도 있고 상태공간 모델의 경우와 같이 확률과정 그 자체일 수도 있습니다. 연구자들은 종종 $Y_{1:n}$에 대한 조건부 확률밀도 $\\pi(y_{1:n}|\\theta)$를 정의하고, $\\theta$에 대한 분포 $\\pi(\\theta)$를 정의하여 $\\pi(y_{1:n})=\\int \\pi(y_{1:n}|\\theta)\\pi(\\theta)d\\theta$를 통해 $\\pi(y_{1:n})$를 찾아냅니다. 시간이력에 대한 동적 선형모델을 소개할 때 여기서도 동일한 절차를 사용할 것입니다. 우선 좀더 단순한 의존구조에 대해 알아보도록 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*조건부 독립*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 단순한 의존 구조는 조건부 독립입니다. 많은 분야에서 $Y_1,\\dots,Y_n$들이 iid (즉, $\\pi(y_{1:n}|\\theta)=\\prod_{i=1}^{n}\\pi(y_i|\\theta)$)라고 가정하는 것은 합리적입니다. 예를들어, $Y_i$가 랜덤 오차의 영향을 받는 반복적인 측정 결과라면, $Y_i=\\theta+\\epsilon_i$이고 $\\epsilon_i$는 측정 장비의 정확성에 따라 평균이 0이고 분산이 $\\sigma^2$인 독립 가우시안 랜덤 오차인 모델로 고려할 수 있습니다. 이는 $\\theta$에 대한 조건부 확률분포 $Y_i$들이 iid라는 것을 의미합니다. 즉, $Y_i|\\theta\\sim N(\\theta,\\sigma^2)$입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유의해야 할 점은 $Y_1,Y_2,\\dots$들은 단지 조건부 독립이라는 것입니다. 관측치 $y_1,\\dots,y_n$들은 $\\theta$ 값에 대한 정보를 제공해 주며, 이 $\\theta$를 통해 다음 관측치 $Y_{n+1}$를 예측하므로 $Y_{n+1}$는 확률론적 관점에서 과거 관측치들 $Y_1,\\dots,Y_n$들과 연관이 있게 됩니다. 이경우 예측 확률밀도는 다음과 같이 계산할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\pi(y_{n+1}|y_{1:n})=\\int \\pi(y_{n+1},\\theta|y_{1:n} d\\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$=\\int \\pi(y_{n+1}|\\theta,y_{1:n})\\pi(\\theta|y_{1:n}) d\\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$=\\int \\pi(y_{n+1}|\\theta)\\pi(\\theta|y_{1:n})d\\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 식의 경우 조건부 독립이라는 가정에 의해 결정된 것이며, $\\pi(\\theta|y_{1:n})$는 $(y_1,\\dots,y_n)$에대한  $\\theta$의 조건부 사후 확률밀도입니다. 사후 확률밀도는 베이즈 법칙에 따라 계산할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\pi(\\theta|y_{1:n})=\\frac{\\pi(y_{1:n}|\\theta)\\pi(\\theta)}{\\pi(y_{1:n})}\\propto\\prod_{t=1}^{n}\\pi(y_t|\\theta)\\pi(\\theta)\\tag{1.1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주변 확률밀도 $\\pi(y_{1:n})$는 $\\theta$와 무관하며 정규화 상수 역할을 합니다. 이에 따라 사후확률밀도는 가능도함수와 사전확률빌도의 곱에 비례하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "흥미로운 점은 조건부 독립이라는 가정이 있으면 사후확률밀도를 순차적(recursively)으로 계산할 수 있다는 것입니다. 이는 모든 이전의 데이터를 저장하고 재가공할 필요가 없다는 것을 의미합니다. 시간 $(n-1)$에서 $\\theta$에 대해 이용가능한 정보는 다음의 조건부확률밀도로 표현됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\pi(\\theta|y_{1:n-1})\\propto\\prod_{t=1}^{n-1}\\pi(y_t|\\theta)\\pi(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 이 확률밀도함수는 시간 $n$에서의 사전확률밀도함수 역할을 하게 됩니다. 새로운 관측치 $y_n$를 얻으면 베이즈 법칙에 따라 조건부 독립 가정에 따라 $\\pi(y_n|\\theta,y_{1:n-1})=\\pi(y_n|\\theta)$로 표현가능한 가능도 함수를 계산하고, 사전확률밀도함수 $\\pi(\\theta|y_{1:n-1})$를 업데이트하면 됩니다. 이에 따라 다음과 같은 결과를 얻게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\pi(\\theta|y_{1:n-1},y_n)\\propto\\pi(\\theta|y_{1:n-1})\\pi(y_n|\\theta)\\propto\\prod_{t=1}^{n-1}\\pi(y_t|\\theta)\\pi(\\theta)\\pi(y_n|\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이는 식 (1.1)과 동일합니다. 사후확률밀도의 순차적 구조는 다음 장들에서 소개될 동적 선형모델과 칼만 필터를 학습하는데 있어 중요한 역할을 하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
